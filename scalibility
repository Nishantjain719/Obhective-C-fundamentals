we could keep track of how busy each server(means keep track of how many requests each server is getting per unit time). and whoever has fewest at this instance wil receive the
next incoming request.
also think about how much work each connection involves on server ask questins like
1. what % of the cpu is actually being consumed right now
how much RAM is actually in use among those servers and pick lowest
so we have to anser about who is least busy or to whom sholud i send this request.
lest ask technical questions - 
how do you route request from client to server?
so why don't we just tell the client directly the ip address of whichever the server is currently the least busy? - we need to involve dns system in this(means DNS server answers the queries
of the form like what's the ip address of yourcompany.com based on currrent load) but here is fault with this design.
if you have isp's DNS server caching lookups as they do even its for some number of minutes the load on these servers is gonna be fluctuating quiety a bit
means if we ansering queries based on this moment of time and those answers are then reused for some number of minutes we might accidentaly end up overwhelming server 1 or 2, so
may be some users experience downtimes or delays even if server N is ideal and has resourses.
or in dns like if one server goes down and you still spiting out one ip address then 1/N of users might go dead end
so solution si load balancer - 
so it acn perform routing function whereby requests just com to lb so lb represents the ip address of yourcompany.com
lb does not take into account of any kind of shared state that must be shared across diffenrt servers
lets talk about when we loging to web next time thereafter website remebers me that i logged in its not username or pass transmitted agin and again to remind server so cookie(fairly
large sudo random value) is passed and planted in my browser(in ram or disk) by server and server has another copy of that number may be in database(or in a file /Temp)
inside of that file or database is the stuff i want to rememberd about me(userbame, password, email) but storing cookies on disk seems to be bad because next server ay be doesn't 
know my session state. so just store cookies in mysql using key-valuse pairs beacuse /temp is unique per server.
but we are centraizing one db.
so we can use one other server anf has hom share his /temp directory to all the other servers like(NFS) DOWNSIDE - We are now centralizing our hardware with just one single file
server.
but its only serving files so may be it can handle more users but if that server dies we are screwed everything is down. because if 10 other server can't share sessions means no 
user is gonna able to login.
use caching engines(redis,etc) -
install cache server on listens on tcp port and you can plop it into memecached(relies on strings being values) generated html file by setting the value for given key what is key- 
if you have user profile then key will be userid(123) and value is just huge chunk of html. when code is to request user profile check cache if its in cache, grab and send it to 
browser else if its not in caache or its 10 minutes old so flush the cache and regenerate it by using normal db queries and save it agian in cache and spit out the results.

use mysql query cache - configure/edit a file on server(my_cnf). restart server. so in future when you exec sql queries the server wiil remember the rows that returend.
if you ask same query again it will return things from cache, and db itself keep track of which data is dirty(menas you have written to it), so cache should be invalidated.
so server will do all that for you.

in web you have mutile webs ervers and those have duplicate installations of your code.


